# ğŸ† Pebble vs SQLite Engine Comparison Tool

A comprehensive, like-for-like benchmark comparison tool between Pebble and SQLite storage engines. This tool tests everything from raw inserts up to large datasets (1M+ records), sequential/random reads, and cleanup operations.

## ğŸš€ Quick Start

```bash
# Run basic comparison (30 seconds)
go test -run=TestEngineComparison -v

# Results Preview:
# ğŸ ENGINE COMPARISON SUMMARY
# ğŸ“Š Total Tests: 3
# ğŸ¥‡ Pebble Wins: 2, ğŸ¥ˆ SQLite Wins: 1
# âš¡ Average Speedup Ratio: 354.94% (Pebble faster)
# ğŸ† Recommended Engine: pebble
```

## ğŸ“Š What Gets Tested

### ğŸ”¥ Raw Insert Performance
- **1K to 1M+ records** - Tests pure write throughput
- **Memory efficiency** - Tracks allocation patterns  
- **Sync lifecycle** - Complete StartNewSync â†’ PutResources â†’ EndSync

### ğŸ“š Read Performance  
- **Sequential Reads** - Bulk pagination operations
- **Random Reads** - Individual record lookups
- **Large datasets** - Up to 100K+ records for realistic testing

### ğŸ”— Complex Operations
- **Grant Operations** - Many-to-many relationships (grants, entitlements, principals)
- **Batch Inserts** - Different batch sizes (100, 1K, 5K per batch)
- **Cleanup/Sync** - Maintenance operations and space reclamation

## ğŸ“ˆ Sample Results

From a recent run on Apple M4 Pro:

```
ğŸ§ª SequentialReads_setup_1000_read_100:
   Pebble: 1,206,025 ops/sec, 0.00 MB memory
   SQLite: 341,443 ops/sec, 0.00 MB memory  
   Winner: pebble (253% faster)

ğŸ§ª RandomReads_setup_1000_read_100:
   Pebble: 216,685 ops/sec, 0.00 MB memory
   SQLite: 22,531 ops/sec, 0.00 MB memory
   Winner: pebble (861% faster)

ğŸ§ª RawInserts_1000:
   Pebble: 41,240 ops/sec, 0.00 MB memory
   SQLite: 82,714 ops/sec, 0.00 MB memory
   Winner: sqlite (50% faster)
```

**Key Insights:**
- âœ… **Pebble dominates read operations** (especially random access)
- âœ… **SQLite wins on small inserts** (better for < 10K records)  
- âœ… **Pebble scales better** with dataset size
- âœ… **Both have excellent memory efficiency** for basic operations

## ğŸ¯ Scale Options

### Small Scale (`-scale=small`)
- **Time**: ~30 seconds
- **Records**: 1K each test
- **Use case**: Quick validation, CI checks

### Medium Scale (`-scale=medium`) 
- **Time**: ~5 minutes  
- **Records**: 10K-50K per test
- **Use case**: Realistic performance assessment

### Large Scale (`-scale=large`)
- **Time**: ~30 minutes
- **Records**: 100K-1M per test  
- **Use case**: Production capacity planning

### Full Suite (`-scale=full`)
- **Time**: ~1 hour
- **Records**: All scenarios
- **Use case**: Comprehensive analysis

## ğŸ› ï¸ Advanced Usage

### Programmatic Access
```go
ctx := context.Background()
suite := NewBenchmarkSuite(ctx)

// Run specific benchmarks
suite.BenchmarkRawInserts(1000000)      // 1M inserts
suite.BenchmarkRandomReads(100000, 5000) // 5K random reads from 100K dataset
suite.BenchmarkSyncCleanup(10)           // 10 sync cleanup

// Generate analysis
suite.generateComparisons()
suite.generateSummary() 
suite.PrintSummary()

// Save detailed JSON results
suite.SaveReport("my_results.json")
```

### CI/CD Integration
```bash
# Run in CI pipeline
go test -run=TestEngineComparison -v -timeout=10m

# Or run custom scales
go run cmd_benchmark.go -scale=medium -output=ci_results.json -quiet
```

## ğŸ“‹ Detailed JSON Output

Every run generates a comprehensive JSON report:

```json
{
  "timestamp": "2025-08-22T11:30:21Z",
  "environment": {
    "os": "darwin", 
    "architecture": "arm64",
    "num_cpu": 12,
    "go_version": "go1.24.6"
  },
  "comparisons": [
    {
      "test_name": "RawInserts_1000000",
      "pebble_ops_per_sec": 45234.56,
      "sqlite_ops_per_sec": 23145.67, 
      "speedup_ratio": 0.954,
      "winner": "pebble",
      "pebble_memory_mb": 12.5,
      "sqlite_memory_mb": 8.3
    }
  ],
  "summary": {
    "recommended_engine": "pebble",
    "pebble_wins": 8,
    "sqlite_wins": 4,
    "average_speedup_ratio": 1.56
  }
}
```

## ğŸ¯ When to Use Each Engine

### Choose Pebble When:
- ğŸ”¥ **Large datasets** (100K+ records)
- ğŸ² **Random access patterns** dominate
- âš¡ **High write throughput** required  
- ğŸ“ˆ **Scaling concerns** (memory, performance)
- ğŸ§¹ **Built-in cleanup** needed

### Choose SQLite When:
- ğŸ”¬ **Small datasets** (< 50K records)
- ğŸ“š **Sequential access** patterns
- âš¡ **Fast startup time** critical
- ğŸ’¾ **Minimal memory** footprint required
- ğŸ”„ **ACID compliance** with complex queries

## ğŸ”§ Key Metrics Explained

### Speedup Ratio
- **Positive**: Pebble is faster (1.5 = 150% faster = 2.5x speed)
- **Negative**: SQLite is faster (-0.5 = SQLite 50% faster)

### Memory Ratio  
- **Positive**: Pebble uses more memory
- **Negative**: Pebble uses less memory

### Winner Selection
Based purely on operations/second. Memory is reported for analysis.

## ğŸ“ Contributing

To add new benchmark categories:

```go
func (bs *BenchmarkSuite) BenchmarkNewFeature(count int) {
    testName := fmt.Sprintf("NewFeature_%d", count)
    
    // Test both engines with identical workloads
    // Pebble test...
    // SQLite test...
}
```

Then add to `RunAllBenchmarks()` or scale methods.

---

**Ready to find out which engine wins for your workload?** 

```bash
go test -run=TestEngineComparison -v
```